failed: 15
results:
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_001
  model_path: null
  params:
    algorithm: ppo
    batch_size: 32
    clip_range: 0.2
    ent_coef: 0.01
    gamma: 0.99
    initial_capital: 50000
    learning_rate: 0.0005
    model_id: model_001
    n_steps: 4096
    name: ppo_model_001
    reward_scaling: 1e-5
    tickers: &id001
    - SPY
    - QQQ
    - DIA
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.824435
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_002
  model_path: null
  params:
    algorithm: ppo
    batch_size: 64
    clip_range: 0.2
    ent_coef: 0.0
    gamma: 0.995
    initial_capital: 50000
    learning_rate: 0.0005
    model_id: model_002
    n_steps: 2048
    name: ppo_model_002
    reward_scaling: 1e-5
    tickers:
    - TSLA
    - NVDA
    - AMD
    - INTC
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.583192
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_003
  model_path: null
  params:
    algorithm: ppo
    batch_size: 64
    clip_range: 0.1
    ent_coef: 0.05
    gamma: 0.99
    initial_capital: 100000
    learning_rate: 0.002
    model_id: model_003
    n_steps: 1024
    name: ppo_model_003
    reward_scaling: 1e-5
    tickers: &id002
    - XLF
    - XLK
    - XLE
    - XLV
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.326986
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_004
  model_path: null
  params:
    algorithm: ppo
    batch_size: 128
    clip_range: 0.3
    ent_coef: 0.05
    gamma: 0.95
    initial_capital: 50000
    learning_rate: 0.001
    model_id: model_004
    n_steps: 1024
    name: ppo_model_004
    reward_scaling: 1e-5
    tickers:
    - AAPL
    - NVDA
    - TSLA
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.341481
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_005
  model_path: null
  params:
    algorithm: ppo
    batch_size: 128
    clip_range: 0.3
    ent_coef: 0.0
    gamma: 0.99
    initial_capital: 100000
    learning_rate: 0.0005
    model_id: model_005
    n_steps: 1024
    name: ppo_model_005
    reward_scaling: 1e-4
    tickers:
    - JPM
    - BAC
    - WFC
    - GS
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.336726
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_006
  model_path: null
  params:
    algorithm: ppo
    batch_size: 128
    clip_range: 0.2
    ent_coef: 0.01
    gamma: 0.995
    initial_capital: 50000
    learning_rate: 0.0005
    model_id: model_006
    n_steps: 4096
    name: ppo_model_006
    reward_scaling: 1e-5
    tickers: *id001
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.355631
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_007
  model_path: null
  params:
    algorithm: ppo
    batch_size: 32
    clip_range: 0.3
    ent_coef: 0.0
    gamma: 0.95
    initial_capital: 50000
    learning_rate: 0.0003
    model_id: model_007
    n_steps: 2048
    name: ppo_model_007
    reward_scaling: 1e-5
    tickers: *id002
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.595937
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_008
  model_path: null
  params:
    algorithm: ppo
    batch_size: 32
    clip_range: 0.1
    ent_coef: 0.01
    gamma: 0.995
    initial_capital: 50000
    learning_rate: 0.001
    model_id: model_008
    n_steps: 2048
    name: ppo_model_008
    reward_scaling: 1e-5
    tickers:
    - AAPL
    - MSFT
    - GOOGL
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.279048
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_009
  model_path: null
  params:
    algorithm: ppo
    batch_size: 64
    clip_range: 0.3
    ent_coef: 0.05
    gamma: 0.995
    initial_capital: 50000
    learning_rate: 0.002
    model_id: model_009
    n_steps: 2048
    name: ppo_model_009
    reward_scaling: 1e-5
    tickers:
    - AAPL
    - GOOGL
    - AMZN
    - MSFT
    - NVDA
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.577913
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_010
  model_path: null
  params:
    algorithm: ppo
    batch_size: 64
    clip_range: 0.3
    ent_coef: 0.01
    gamma: 0.995
    initial_capital: 200000
    learning_rate: 0.001
    model_id: model_010
    n_steps: 4096
    name: ppo_model_010
    reward_scaling: 1e-3
    tickers: *id002
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.278537
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_011
  model_path: null
  params:
    algorithm: ppo
    batch_size: 32
    clip_range: 0.3
    ent_coef: 0.01
    gamma: 0.99
    initial_capital: 200000
    learning_rate: 0.0001
    model_id: model_011
    n_steps: 1024
    name: ppo_model_011
    reward_scaling: 1e-4
    tickers: &id003
    - MSFT
    - AMZN
    - META
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.560852
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_012
  model_path: null
  params:
    algorithm: ppo
    batch_size: 64
    clip_range: 0.2
    ent_coef: 0.01
    gamma: 0.95
    initial_capital: 100000
    learning_rate: 0.001
    model_id: model_012
    n_steps: 2048
    name: ppo_model_012
    reward_scaling: 1e-3
    tickers:
    - AAPL
    - MSFT
    - NVDA
    - GOOGL
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.6212
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_013
  model_path: null
  params:
    algorithm: ppo
    batch_size: 32
    clip_range: 0.3
    ent_coef: 0.0
    gamma: 0.995
    initial_capital: 100000
    learning_rate: 0.0003
    model_id: model_013
    n_steps: 4096
    name: ppo_model_013
    reward_scaling: 1e-4
    tickers: *id003
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.378657
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_014
  model_path: null
  params:
    algorithm: ppo
    batch_size: 128
    clip_range: 0.3
    ent_coef: 0.0
    gamma: 0.995
    initial_capital: 200000
    learning_rate: 0.001
    model_id: model_014
    n_steps: 4096
    name: ppo_model_014
    reward_scaling: 1e-5
    tickers: *id001
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.361198
- error: can't multiply sequence by non-int of type 'numpy.float64'
  model_id: model_015
  model_path: null
  params:
    algorithm: ppo
    batch_size: 32
    clip_range: 0.3
    ent_coef: 0.01
    gamma: 0.95
    initial_capital: 200000
    learning_rate: 0.001
    model_id: model_015
    n_steps: 1024
    name: ppo_model_015
    reward_scaling: 1e-3
    tickers: *id003
    timesteps: 1500000
  success: false
  traceback: "Traceback (most recent call last):\n  File \"/home/salt/CodingProjects/RLFI/src/autotest/automated_trainer.py\"\
    , line 162, in train_model\n    model = trainer.train(total_timesteps=params['timesteps'],\
    \ eval_env=eval_env)\n  File \"/home/salt/CodingProjects/RLFI/src/agents/trainer.py\"\
    , line 111, in train\n    self.model.learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/ppo/ppo.py\"\
    , line 311, in learn\n    return super().learn(\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 324, in learn\n    continue_training = self.collect_rollouts(self.env,\
    \ callback, self.rollout_buffer, n_rollout_steps=self.n_steps)\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/on_policy_algorithm.py\"\
    , line 218, in collect_rollouts\n    new_obs, rewards, dones, infos = env.step(clipped_actions)\n\
    \  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/base_vec_env.py\"\
    , line 222, in step\n    return self.step_wait()\n  File \"/home/salt/CodingProjects/RLFI/venv/lib/python3.10/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py\"\
    , line 59, in step_wait\n    obs, self.buf_rews[env_idx], terminated, truncated,\
    \ self.buf_infos[env_idx] = self.envs[env_idx].step(  # type: ignore[assignment]\n\
    \  File \"/home/salt/CodingProjects/RLFI/src/environment/trading_env.py\", line\
    \ 111, in step\n    reward = portfolio_return * self.reward_scaling\nTypeError:\
    \ can't multiply sequence by non-int of type 'numpy.float64'\n"
  training_time: 3.375555
successful: 0
total_models: 15
